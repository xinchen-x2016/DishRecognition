{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torchvision import models,transforms,datasets\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_gpu = False\n",
    "use_gpu = torch.cuda.is_available()\n",
    "def gpu(x,use_gpu=use_gpu):\n",
    "    if use_gpu:\n",
    "        return x.cuda()\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Dataset'\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "vgg_format = transforms.Compose([\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])\n",
    "\n",
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    # override the __getitem__ method. this is the method dataloader calls\n",
    "    def __getitem__(self, index):\n",
    "        # this is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # the image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path\n",
    "\n",
    "dsets = {x: ImageFolderWithPaths(os.path.join(data_dir, x), vgg_format)\n",
    "         for x in ['train', 'val', 'test']}\n",
    "    \n",
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'val','test']}\n",
    "dset_classes = dsets['train'].classes\n",
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=64,\n",
    "                                               shuffle=True, num_workers=6)\n",
    "                for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean IngredientList.txt and output the doublets\n",
    "ing_list = './IngredientList.txt'\n",
    "text_file = open(\"./IngredientList.txt\", \"r\")\n",
    "lines = text_file.read().split('\\n')\n",
    "ing_dict = {}\n",
    "i = 0\n",
    "for l in lines:\n",
    "    ing_dict[i] = l\n",
    "    i += 1\n",
    "for key, val in ing_dict.items():\n",
    "    val = val.lower()\n",
    "    if \"\\ufeff\" in val:\n",
    "        val = val.replace('\\ufeff','')\n",
    "    if \"of\" in val:\n",
    "        val = val.replace('of ','')\n",
    "    if \"chiffonade\" in val:\n",
    "        val = val.replace('chiffonade','sliced')\n",
    "    if \"slices\" in val:\n",
    "        val = val.replace('slices','sliced')\n",
    "    if 'julienned' in val:\n",
    "        val = val.replace('julienned', 'shredded')\n",
    "    val = val.replace(' ', '')\n",
    "    ing_dict[key] = val\n",
    "\n",
    "cut_set = {0: \"batonnet\", 1: \"minced\", 2: \"sliced\", 3: \"crushed\", 4: \"shredded\", 5: \"brunoisediced\", 6: \"chopped\", 7:\"chunks\", 8: \"fried\", 9: \"steamed\", 10: \"boiled\", 11: \"pickled\", 12: \"seared\", 13: \"dried\"}\n",
    "\n",
    "new_ing_dict = {}\n",
    "ing_set = {}\n",
    "i, j = 0, 0\n",
    "\n",
    "for idx, val in ing_dict.items():\n",
    "    new_ing_dict[idx] = [-1,-1]    #note -1 if missing data\n",
    "    # find cut\n",
    "    for jdx, cut in cut_set.items():\n",
    "        if cut in val:\n",
    "            new_ing_dict[idx][0] = jdx\n",
    "            val = val.replace(cut, '')\n",
    "    # find ingre\n",
    "    if not val in ing_set.values():\n",
    "        ing_set[j] = val\n",
    "        j += 1\n",
    "        new_ing_dict[idx][1] = j\n",
    "    else:\n",
    "        new_ing_dict[idx][1] = list(ing_set.keys())[list(ing_set.values()).index(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'greenonion',\n",
       " 1: 'whiteonion',\n",
       " 2: 'ham',\n",
       " 3: 'carrot',\n",
       " 4: 'hobblockscarrot',\n",
       " 5: 'blacksesame',\n",
       " 6: 'whitesesame',\n",
       " 7: 'pepper',\n",
       " 8: 'wholegreenpepper',\n",
       " 9: 'chineseparsleycoriander',\n",
       " 10: 'beansprouts',\n",
       " 11: 'bacon',\n",
       " 12: 'tomatosclices',\n",
       " 13: 'cherrytomato',\n",
       " 14: 'greenvegetables',\n",
       " 15: 'cornkernels',\n",
       " 16: 'cornblocks',\n",
       " 17: 'bittergourd',\n",
       " 18: 'broccoli',\n",
       " 19: 'cauliflower',\n",
       " 20: 'toast',\n",
       " 21: 'bread',\n",
       " 22: 'chinesemahogany',\n",
       " 23: 'crabsticks',\n",
       " 24: 'bambooshootstips',\n",
       " 25: 'chivepieces',\n",
       " 26: 'chives',\n",
       " 27: 'onion',\n",
       " 28: 'pumpkinblocks',\n",
       " 29: 'groundnutkernels',\n",
       " 30: 'lemon',\n",
       " 31: 'shelledfreshshrimps',\n",
       " 32: 'seashrimp',\n",
       " 33: 'freshshrimp',\n",
       " 34: 'crayfish',\n",
       " 35: 'cucumber',\n",
       " 36: 'hobblockscucumber',\n",
       " 37: 'hotanddrychili',\n",
       " 38: 'hotanddrypepper',\n",
       " 39: 'hotanddrypepperpowder',\n",
       " 40: 'purplecabbage',\n",
       " 41: 'chinesecabbage',\n",
       " 42: 'blackfungus',\n",
       " 43: 'perillacrispatanaka',\n",
       " 44: 'ginger',\n",
       " 45: 'scrambledegg',\n",
       " 46: 'eggcake',\n",
       " 47: 'eggcrepe',\n",
       " 48: 'spicedcornedegg',\n",
       " 49: 'eggyolk',\n",
       " 50: 'eggcustard',\n",
       " 51: 'boildegg',\n",
       " 52: 'boildeggs',\n",
       " 53: 'eggdrop',\n",
       " 54: 'quaileggs',\n",
       " 55: 'pork',\n",
       " 56: 'wolfberry',\n",
       " 57: 'streakypork',\n",
       " 58: 'curedmeat',\n",
       " 59: 'kaleborecole',\n",
       " 60: 'porkintestines',\n",
       " 61: 'lettuce',\n",
       " 62: 'reddates',\n",
       " 63: 'kiwi',\n",
       " 64: 'garlicclove',\n",
       " 65: 'garlic',\n",
       " 66: 'garlicbulb',\n",
       " 67: 'lentinusedodes',\n",
       " 68: 'pleurotusostreatus',\n",
       " 69: 'poplarmushroom',\n",
       " 70: 'mushroom',\n",
       " 71: 'whitebeechmushroom',\n",
       " 72: 'yam',\n",
       " 73: 'whiteyam',\n",
       " 74: 'strawberry',\n",
       " 75: 'seacucumber',\n",
       " 76: 'shanghaicabbage',\n",
       " 77: 'asparagus',\n",
       " 78: 'bambooshoots',\n",
       " 79: 'rice',\n",
       " 80: 'meatballs',\n",
       " 81: 'beafballs',\n",
       " 82: 'shrimpballs',\n",
       " 83: 'fishballs',\n",
       " 84: 'blueberryjam',\n",
       " 85: 'orange',\n",
       " 86: 'mango',\n",
       " 87: 'noodles',\n",
       " 88: 'beef',\n",
       " 89: 'fattybeef',\n",
       " 90: 'tofu',\n",
       " 91: 'chibabeancurd',\n",
       " 92: 'fishbeancurd',\n",
       " 93: 'stinkytofu',\n",
       " 94: 'beancurd',\n",
       " 95: 'hobblockspotato',\n",
       " 96: 'potato',\n",
       " 97: 'mashedpotatoes',\n",
       " 98: 'chilioil',\n",
       " 99: 'chilisaurce',\n",
       " 100: 'chilipowder',\n",
       " 101: 'garlicsproutpieces',\n",
       " 102: 'garlicsprout',\n",
       " 103: 'garlicleaves',\n",
       " 104: 'redpeppers',\n",
       " 105: 'capsicumannumfasciculatum',\n",
       " 106: 'kelp',\n",
       " 107: 'bullfrog',\n",
       " 108: 'caviar',\n",
       " 109: 'lotusroot',\n",
       " 110: 'lotusrootbox',\n",
       " 111: 'celtucesclices',\n",
       " 112: 'celtuce',\n",
       " 113: 'sweetpotato',\n",
       " 114: 'sausage',\n",
       " 115: 'cabbage',\n",
       " 116: 'spareribs',\n",
       " 117: 'clams',\n",
       " 118: 'liliumbrownii',\n",
       " 119: 'fermentedvegetables',\n",
       " 120: 'double-sideegg',\n",
       " 121: 'radish',\n",
       " 122: 'hobblocksradish',\n",
       " 123: 'mashedradish',\n",
       " 124: 'flatbread',\n",
       " 125: 'springrolls',\n",
       " 126: 'chicken',\n",
       " 127: 'tentaclessquid',\n",
       " 128: 'squidpieces',\n",
       " 129: 'squidrings',\n",
       " 130: 'whitegourd',\n",
       " 131: 'piecesbeancurd',\n",
       " 132: 'yellowpeaches',\n",
       " 133: 'pineapple',\n",
       " 134: 'eggplant',\n",
       " 135: 'eggplantslice',\n",
       " 136: 'hobblockseggplant',\n",
       " 137: 'eggplantsticks',\n",
       " 138: 'watermellon',\n",
       " 139: 'gluten',\n",
       " 140: 'dumplings',\n",
       " 141: 'breadstick',\n",
       " 142: 'hotmustard',\n",
       " 143: 'sesamesauce',\n",
       " 144: 'soya-beansprout',\n",
       " 145: 'beeftripe',\n",
       " 146: 'waterspinach',\n",
       " 147: 'barbecuedpork',\n",
       " 148: 'chickenfeet',\n",
       " 149: 'coldricenoodles',\n",
       " 150: 'mutton',\n",
       " 151: 'smallloafbread',\n",
       " 152: 'starchsheet',\n",
       " 153: 'yuba',\n",
       " 154: 'okra',\n",
       " 155: 'chestnut',\n",
       " 156: 'preservedegg',\n",
       " 157: 'wholepreservedegg',\n",
       " 158: 'laver',\n",
       " 159: 'doughtwist',\n",
       " 160: 'longan',\n",
       " 161: 'stewedpork',\n",
       " 162: 'beans',\n",
       " 163: 'sweetfermentedflourpaste',\n",
       " 164: 'riversnail',\n",
       " 165: 'spinach',\n",
       " 166: 'seasedge',\n",
       " 167: 'bracken',\n",
       " 168: 'coprinuscomatus',\n",
       " 169: 'limeleaves',\n",
       " 170: 'lemongrass',\n",
       " 171: 'lime',\n",
       " 172: 'chickenwings',\n",
       " 173: 'snowpeas',\n",
       " 174: 'vegetable',\n",
       " 175: 'saltedegg',\n",
       " 176: 'curry',\n",
       " 177: 'blackpepperpowder',\n",
       " 178: 'flour',\n",
       " 179: 'wholeblackchicken',\n",
       " 180: 'blackchicken',\n",
       " 181: 'celerystalk',\n",
       " 182: 'celeryleaves',\n",
       " 183: 'celery',\n",
       " 184: 'banana',\n",
       " 185: 'apple',\n",
       " 186: 'loofah',\n",
       " 187: 'fish',\n",
       " 188: 'zucchini',\n",
       " 189: 'wholechicken',\n",
       " 190: 'tenderloin',\n",
       " 191: 'whitecongee',\n",
       " 192: 'spaghetti',\n",
       " 193: 'steak',\n",
       " 194: 'cuminpowder',\n",
       " 195: 'beeftripes',\n",
       " 196: 'pinenuts',\n",
       " 197: 'gemelli',\n",
       " 198: 'koreanchilisauce',\n",
       " 199: 'kidneybean',\n",
       " 200: 'zanthoxylumfagara',\n",
       " 201: 'ricenoodle',\n",
       " 202: 'yubaskin',\n",
       " 203: 'saladdressing',\n",
       " 204: 'soyabean',\n",
       " 205: 'fernrootnoodles',\n",
       " 206: 'ketchup',\n",
       " 207: 'mintleaf',\n",
       " 208: 'soysauce',\n",
       " 209: 'babychinesecabbage',\n",
       " 210: 'water',\n",
       " 211: 'lotusseeds',\n",
       " 212: 'azukibean',\n",
       " 213: 'greensoybean',\n",
       " 214: 'parsley',\n",
       " 215: 'duckneck',\n",
       " 216: 'thickbroad-beansauce',\n",
       " 217: 'enokimushroom',\n",
       " 218: 'crystalsugar',\n",
       " 219: 'cashew',\n",
       " 220: 'bun',\n",
       " 221: 'soursauce',\n",
       " 222: 'porkleg',\n",
       " 223: 'bayleaf',\n",
       " 224: 'shumai',\n",
       " 225: 'craproe',\n",
       " 226: 'shrimpeggs',\n",
       " 227: 'buttonmushroom',\n",
       " 228: 'coconutwater',\n",
       " 229: 'glutinousrice',\n",
       " 230: 'sweetpotatostarchnoodles',\n",
       " 231: 'vermicelli',\n",
       " 232: 'fermentedsoyabeans',\n",
       " 233: 'ricedumpling',\n",
       " 234: 'sweetenedbeanpaste',\n",
       " 235: 'sweetdumplings',\n",
       " 236: 'ricenoodleroll',\n",
       " 237: 'pea',\n",
       " 238: 'porkfloss',\n",
       " 239: 'scallionpancake',\n",
       " 240: 'blackrice',\n",
       " 241: 'smallcrispyrice',\n",
       " 242: 'coconutcake',\n",
       " 243: 'coconutstuffing',\n",
       " 244: 'mussels',\n",
       " 245: 'porklungs',\n",
       " 246: 'crispysausage',\n",
       " 247: 'codonopsispilosula',\n",
       " 248: 'radixastragali',\n",
       " 249: 'americangenseng',\n",
       " 250: 'cordycepssinensis',\n",
       " 251: 'aniseed',\n",
       " 252: 'raisin',\n",
       " 253: 'sucklingpig',\n",
       " 254: 'twistedroll',\n",
       " 255: 'grape',\n",
       " 256: 'porkpaste',\n",
       " 257: 'cheese',\n",
       " 258: 'wonton',\n",
       " 259: 'duckhead',\n",
       " 260: 'chinesekale',\n",
       " 261: 'chickenlegs',\n",
       " 262: 'sweetandsoursauce',\n",
       " 263: 'fishhead',\n",
       " 264: 'ricepowder',\n",
       " 265: 'scallop',\n",
       " 266: 'macaroni',\n",
       " 267: 'ribbonfish',\n",
       " 268: 'tea-leaves',\n",
       " 269: 'millet',\n",
       " 270: 'preservedvegetables',\n",
       " 271: 'coixseed',\n",
       " 272: 'greenbeans',\n",
       " 273: 'whitefungus',\n",
       " 274: 'crucian',\n",
       " 275: 'vinegar',\n",
       " 276: 'pancakes',\n",
       " 277: 'crispbread',\n",
       " 278: 'crab',\n",
       " 279: 'soya-beanmilk',\n",
       " 280: 'fermentedsoybeanpaste',\n",
       " 281: 'oystersauce',\n",
       " 282: 'greensoybeans',\n",
       " 283: 'cherry',\n",
       " 284: 'pigears',\n",
       " 285: ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [1, 1],\n",
       " 1: [2, 0],\n",
       " 2: [12, 0],\n",
       " 3: [-1, 2],\n",
       " 4: [5, 3],\n",
       " 5: [4, 2],\n",
       " 6: [-1, 2],\n",
       " 7: [2, 2],\n",
       " 8: [5, 4],\n",
       " 9: [2, 3],\n",
       " 10: [0, 3],\n",
       " 11: [4, 3],\n",
       " 12: [-1, 5],\n",
       " 13: [-1, 6],\n",
       " 14: [-1, 7],\n",
       " 15: [3, 8],\n",
       " 16: [4, 7],\n",
       " 17: [2, 7],\n",
       " 18: [12, 7],\n",
       " 19: [-1, 7],\n",
       " 20: [-1, 9],\n",
       " 21: [-1, 10],\n",
       " 22: [-1, 11],\n",
       " 23: [-1, 12],\n",
       " 24: [-1, 13],\n",
       " 25: [2, 14],\n",
       " 26: [-1, 13],\n",
       " 27: [-1, 15],\n",
       " 28: [2, 14],\n",
       " 29: [-1, 16],\n",
       " 30: [-1, 17],\n",
       " 31: [2, 18],\n",
       " 32: [-1, 19],\n",
       " 33: [-1, 20],\n",
       " 34: [-1, 21],\n",
       " 35: [-1, 22],\n",
       " 36: [-1, 23],\n",
       " 37: [-1, 24],\n",
       " 38: [-1, 25],\n",
       " 39: [-1, 26],\n",
       " 40: [6, 27],\n",
       " 41: [-1, 26],\n",
       " 42: [4, 28],\n",
       " 43: [2, 27],\n",
       " 44: [5, 27],\n",
       " 45: [-1, 29],\n",
       " 46: [-1, 30],\n",
       " 47: [3, 29],\n",
       " 48: [-1, 31],\n",
       " 49: [-1, 32],\n",
       " 50: [13, 33],\n",
       " 51: [-1, 34],\n",
       " 52: [-1, 35],\n",
       " 53: [4, 36],\n",
       " 54: [0, 35],\n",
       " 55: [-1, 37],\n",
       " 56: [2, 35],\n",
       " 57: [5, 35],\n",
       " 58: [3, 38],\n",
       " 59: [-1, 39],\n",
       " 60: [-1, 40],\n",
       " 61: [2, 41],\n",
       " 62: [-1, 42],\n",
       " 63: [-1, 43],\n",
       " 64: [-1, 44],\n",
       " 65: [2, 45],\n",
       " 66: [4, 44],\n",
       " 67: [6, 44],\n",
       " 68: [-1, 46],\n",
       " 69: [-1, 47],\n",
       " 70: [3, 48],\n",
       " 71: [-1, 49],\n",
       " 72: [-1, 50],\n",
       " 73: [9, 51],\n",
       " 74: [2, 52],\n",
       " 75: [-1, 53],\n",
       " 76: [-1, 54],\n",
       " 77: [4, 47],\n",
       " 78: [-1, 55],\n",
       " 79: [1, 56],\n",
       " 80: [-1, 57],\n",
       " 81: [1, 55],\n",
       " 82: [4, 55],\n",
       " 83: [2, 58],\n",
       " 84: [2, 55],\n",
       " 85: [7, 55],\n",
       " 86: [7, 57],\n",
       " 87: [7, 59],\n",
       " 88: [-1, 60],\n",
       " 89: [-1, 61],\n",
       " 90: [-1, 62],\n",
       " 91: [9, 21],\n",
       " 92: [-1, 63],\n",
       " 93: [-1, 64],\n",
       " 94: [-1, 65],\n",
       " 95: [3, 66],\n",
       " 96: [-1, 67],\n",
       " 97: [-1, 68],\n",
       " 98: [2, 67],\n",
       " 99: [5, 67],\n",
       " 100: [-1, 69],\n",
       " 101: [-1, 70],\n",
       " 102: [13, 71],\n",
       " 103: [-1, 72],\n",
       " 104: [7, 73],\n",
       " 105: [-1, 74],\n",
       " 106: [2, 72],\n",
       " 107: [-1, 75],\n",
       " 108: [-1, 76],\n",
       " 109: [-1, 77],\n",
       " 110: [-1, 78],\n",
       " 111: [7, 79],\n",
       " 112: [4, 78],\n",
       " 113: [-1, 80],\n",
       " 114: [-1, 81],\n",
       " 115: [-1, 82],\n",
       " 116: [-1, 83],\n",
       " 117: [-1, 84],\n",
       " 118: [-1, 85],\n",
       " 119: [2, 86],\n",
       " 120: [-1, 87],\n",
       " 121: [-1, 88],\n",
       " 122: [7, 89],\n",
       " 123: [2, 88],\n",
       " 124: [2, 90],\n",
       " 125: [7, 91],\n",
       " 126: [-1, 92],\n",
       " 127: [-1, 93],\n",
       " 128: [-1, 94],\n",
       " 129: [13, 95],\n",
       " 130: [-1, 96],\n",
       " 131: [2, 97],\n",
       " 132: [4, 96],\n",
       " 133: [-1, 98],\n",
       " 134: [0, 96],\n",
       " 135: [-1, 99],\n",
       " 136: [-1, 100],\n",
       " 137: [-1, 101],\n",
       " 138: [-1, 102],\n",
       " 139: [5, 103],\n",
       " 140: [-1, 104],\n",
       " 141: [11, 105],\n",
       " 142: [11, 106],\n",
       " 143: [11, 105],\n",
       " 144: [4, 107],\n",
       " 145: [-1, 106],\n",
       " 146: [-1, 108],\n",
       " 147: [-1, 109],\n",
       " 148: [2, 110],\n",
       " 149: [7, 109],\n",
       " 150: [-1, 111],\n",
       " 151: [-1, 112],\n",
       " 152: [0, 113],\n",
       " 153: [4, 112],\n",
       " 154: [7, 114],\n",
       " 155: [2, 115],\n",
       " 156: [-1, 116],\n",
       " 157: [2, 115],\n",
       " 158: [-1, 117],\n",
       " 159: [-1, 118],\n",
       " 160: [-1, 119],\n",
       " 161: [-1, 120],\n",
       " 162: [8, 121],\n",
       " 163: [8, 120],\n",
       " 164: [2, 122],\n",
       " 165: [0, 121],\n",
       " 166: [-1, 123],\n",
       " 167: [4, 121],\n",
       " 168: [11, 124],\n",
       " 169: [11, 121],\n",
       " 170: [-1, 125],\n",
       " 171: [-1, 126],\n",
       " 172: [7, 127],\n",
       " 173: [5, 126],\n",
       " 174: [-1, 128],\n",
       " 175: [-1, 129],\n",
       " 176: [-1, 130],\n",
       " 177: [7, 131],\n",
       " 178: [13, 132],\n",
       " 179: [-1, 133],\n",
       " 180: [-1, 134],\n",
       " 181: [-1, 135],\n",
       " 182: [-1, 136],\n",
       " 183: [0, 134],\n",
       " 184: [-1, 137],\n",
       " 185: [-1, 138],\n",
       " 186: [-1, 139],\n",
       " 187: [-1, 140],\n",
       " 188: [7, 139],\n",
       " 189: [-1, 141],\n",
       " 190: [8, 142],\n",
       " 191: [8, 141],\n",
       " 192: [11, 143],\n",
       " 193: [-1, 144],\n",
       " 194: [-1, 145],\n",
       " 195: [4, 146],\n",
       " 196: [-1, 147],\n",
       " 197: [11, 78],\n",
       " 198: [2, 148],\n",
       " 199: [7, 147],\n",
       " 200: [-1, 149],\n",
       " 201: [9, 150],\n",
       " 202: [2, 151],\n",
       " 203: [7, 150],\n",
       " 204: [9, 152],\n",
       " 205: [9, 151],\n",
       " 206: [-1, 153],\n",
       " 207: [-1, 154],\n",
       " 208: [2, 155],\n",
       " 209: [-1, 156],\n",
       " 210: [7, 157],\n",
       " 211: [3, 156],\n",
       " 212: [-1, 158],\n",
       " 213: [-1, 159],\n",
       " 214: [8, 160],\n",
       " 215: [-1, 161],\n",
       " 216: [-1, 162],\n",
       " 217: [-1, 163],\n",
       " 218: [1, 162],\n",
       " 219: [11, 162],\n",
       " 220: [-1, 164],\n",
       " 221: [-1, 165],\n",
       " 222: [-1, 166],\n",
       " 223: [-1, 167],\n",
       " 224: [-1, 168],\n",
       " 225: [-1, 169],\n",
       " 226: [-1, 170],\n",
       " 227: [-1, 171],\n",
       " 228: [-1, 172],\n",
       " 229: [-1, 173],\n",
       " 230: [-1, 174],\n",
       " 231: [11, 175],\n",
       " 232: [-1, 176],\n",
       " 233: [-1, 177],\n",
       " 234: [-1, 178],\n",
       " 235: [8, 179],\n",
       " 236: [-1, 180],\n",
       " 237: [7, 181],\n",
       " 238: [2, 182],\n",
       " 239: [-1, 181],\n",
       " 240: [-1, 183],\n",
       " 241: [-1, 184],\n",
       " 242: [5, 183],\n",
       " 243: [2, 185],\n",
       " 244: [7, 186],\n",
       " 245: [-1, 187],\n",
       " 246: [2, 188],\n",
       " 247: [7, 187],\n",
       " 248: [-1, 187],\n",
       " 249: [2, 189],\n",
       " 250: [10, 126],\n",
       " 251: [10, 190],\n",
       " 252: [2, 191],\n",
       " 253: [7, 190],\n",
       " 254: [0, 190],\n",
       " 255: [-1, 192],\n",
       " 256: [-1, 193],\n",
       " 257: [-1, 194],\n",
       " 258: [-1, 195],\n",
       " 259: [-1, 196],\n",
       " 260: [-1, 197],\n",
       " 261: [-1, 198],\n",
       " 262: [-1, 199],\n",
       " 263: [-1, 200],\n",
       " 264: [-1, 201],\n",
       " 265: [-1, 202],\n",
       " 266: [8, 203],\n",
       " 267: [-1, 204],\n",
       " 268: [-1, 205],\n",
       " 269: [-1, 206],\n",
       " 270: [-1, 207],\n",
       " 271: [-1, 208],\n",
       " 272: [-1, 209],\n",
       " 273: [-1, 210],\n",
       " 274: [-1, 211],\n",
       " 275: [-1, 212],\n",
       " 276: [-1, 213],\n",
       " 277: [-1, 214],\n",
       " 278: [-1, 215],\n",
       " 279: [-1, 216],\n",
       " 280: [-1, 217],\n",
       " 281: [-1, 218],\n",
       " 282: [-1, 219],\n",
       " 283: [-1, 220],\n",
       " 284: [9, 221],\n",
       " 285: [-1, 222],\n",
       " 286: [-1, 223],\n",
       " 287: [-1, 224],\n",
       " 288: [-1, 225],\n",
       " 289: [-1, 226],\n",
       " 290: [-1, 227],\n",
       " 291: [-1, 228],\n",
       " 292: [-1, 229],\n",
       " 293: [-1, 230],\n",
       " 294: [-1, 231],\n",
       " 295: [-1, 232],\n",
       " 296: [-1, 233],\n",
       " 297: [-1, 234],\n",
       " 298: [-1, 235],\n",
       " 299: [-1, 236],\n",
       " 300: [-1, 237],\n",
       " 301: [-1, 238],\n",
       " 302: [-1, 239],\n",
       " 303: [-1, 240],\n",
       " 304: [-1, 241],\n",
       " 305: [-1, 242],\n",
       " 306: [-1, 243],\n",
       " 307: [4, 244],\n",
       " 308: [-1, 245],\n",
       " 309: [-1, 246],\n",
       " 310: [-1, 247],\n",
       " 311: [-1, 248],\n",
       " 312: [-1, 249],\n",
       " 313: [-1, 250],\n",
       " 314: [-1, 251],\n",
       " 315: [-1, 252],\n",
       " 316: [-1, 253],\n",
       " 317: [-1, 254],\n",
       " 318: [9, 255],\n",
       " 319: [-1, 256],\n",
       " 320: [-1, 257],\n",
       " 321: [-1, 258],\n",
       " 322: [-1, 259],\n",
       " 323: [-1, 260],\n",
       " 324: [-1, 261],\n",
       " 325: [-1, 262],\n",
       " 326: [-1, 189],\n",
       " 327: [4, 126],\n",
       " 328: [-1, 263],\n",
       " 329: [-1, 264],\n",
       " 330: [9, 265],\n",
       " 331: [-1, 266],\n",
       " 332: [-1, 267],\n",
       " 333: [-1, 268],\n",
       " 334: [-1, 269],\n",
       " 335: [-1, 270],\n",
       " 336: [-1, 271],\n",
       " 337: [-1, 272],\n",
       " 338: [-1, 273],\n",
       " 339: [-1, 274],\n",
       " 340: [-1, 275],\n",
       " 341: [-1, 276],\n",
       " 342: [-1, 277],\n",
       " 343: [-1, 278],\n",
       " 344: [7, 86],\n",
       " 345: [-1, 279],\n",
       " 346: [-1, 280],\n",
       " 347: [-1, 281],\n",
       " 348: [-1, 282],\n",
       " 349: [7, 116],\n",
       " 350: [-1, 283],\n",
       " 351: [-1, 284],\n",
       " 352: [4, 285],\n",
       " 353: [-1, 286]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ing_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(input, p=2, dim=1, eps=1e-12):\n",
    "    return input / input.norm(p,dim,keepdim=True).clamp(min=eps).expand_as(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(embedding, self).__init__()\n",
    "        # new feature\n",
    "        self.feature_emb = nn.Sequential(\n",
    "            nn.Linear(512, 172), \n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        # ingredient\n",
    "        self.ingredient_emb = nn.Sequential(\n",
    "            nn.Linear(172, 353),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "         # cutting\n",
    "        self.cutting_emb = nn.Sequential(\n",
    "            nn.Linear(172, 14),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 512, -1)\n",
    "        x = torch.transpose(x,1,2)\n",
    "        fea_embedding = self.feature_emb(x)\n",
    "        fea_embedding = norm(fea_embedding)\n",
    "        ing_embedding = self.ingredient_emb(fea_embedding)\n",
    "        cut_embedding = self.cutting_emb(fea_embedding)\n",
    "        return fea_embedding, ing_embedding, cut_embedding     # 3-d [batch_size,self_size,49]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_unflatten(tsor, dim):\n",
    "    b = tsor.cpu().numpy()\n",
    "    c = []\n",
    "    for val in b:\n",
    "        c.append([(int)(val/dim),val%dim])\n",
    "    c = np.asarray(c)\n",
    "    c = c.reshape(b.shape)\n",
    "    new_tensor = torch.from_numpy(c)\n",
    "    return new_tensor\n",
    "\n",
    "def pooling(ing_emb, cut_emb):               #input_size = [64,49,353/14]\n",
    "    # get the i-th region of ingredient j\n",
    "    ing_max, idx = torch.max(ing_emb, dim=1)    #[64,354]   idx_val in [0,48]\n",
    "\n",
    "    p_ingre = ing_max\n",
    "    \n",
    "    # pooling cutting and cooking method of i-th region\n",
    "    p_cut = torch.zeros(cut_emb.size(0),ing_emb.size(2),cut_emb.size(2))\n",
    "\n",
    "    i = 0\n",
    "    for ing_batch in idx:           #ing_batch    positions of most popular grid of each ingre in a batch, size=354\n",
    "        for j in range(ing_max.size(1)):\n",
    "            p = ing_batch[j]\n",
    "#             for k in range(cut_emb.size(2)):\n",
    "            p_cut[i,j,:] = cut_emb[i,p,:]\n",
    "#         print(i)\n",
    "        i += 1\n",
    "    return p_ingre, p_cut           # p_ingre:[64,353],  p_cut:[64,353,14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recipe retrival from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original ingredient label is represented as a list\n",
    "# output is a list of doublet(ing, cut)\n",
    "def recipe_retrival(ingre_label):\n",
    "    res = []\n",
    "    for idx, val in enumerate(ingre_label):\n",
    "        if val == 1:\n",
    "            doublet = new_ing_dict[idx]             \n",
    "            res.append(doublet)\n",
    "    return res\n",
    "\n",
    "IngreLabel = open('IngreLabel.txt', 'r').read().split('\\n')[:-1]   # list of str\n",
    "for i in range(len(IngreLabel)):\n",
    "    IngreLabel[i] = IngreLabel[i].split()                    # list of list, element is str\n",
    "\n",
    "# Get t_ingre from path\n",
    "def Get_ingre(path):\n",
    "    ID = path[11]\n",
    "    if ID == 'r':    #train\n",
    "        path = path[15:]\n",
    "    elif ID == 'a':  #val\n",
    "        path = path[13:]\n",
    "    else:            #test\n",
    "        path = path[14:]\n",
    "    # path has the same format of that in IngreLabel.txt\n",
    "    for pil in IngreLabel:\n",
    "        if pil[0] == path:\n",
    "            ingre = [int(i) for i in pil[1:]]\n",
    "            ingre = np.asarray(ingre)\n",
    "            ingre = torch.from_numpy(ingre)\n",
    "            return ingre\n",
    "\n",
    "# Get t_cut from t_ingre\n",
    "def Get_cut(t_ingre):\n",
    "    t_cut = torch.zeros([cutDim, ingDim])\n",
    "    recipe = recipe_retrival(t_ingre)\n",
    "    a,b = zip(*recipe)\n",
    "    c = list(a)   # cut\n",
    "    t = list(b)   # ingre\n",
    "    for i in range(len(c)):\n",
    "        if c[i] != 0:\n",
    "            t_cut[c[i],t[i]] = 1 \n",
    "    t_cut = torch.transpose(t_cut,0,1)\n",
    "    return t_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IngreLabel[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all recipes from IngreLabel.txt\n",
    "All_recipe = []\n",
    "for p in IngreLabel:\n",
    "    ingre = [int(i) for i in p[1:]]\n",
    "    r = recipe_retrival(ingre)\n",
    "    All_recipe.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[5, 4], [-1, 6], [-1, 47]],\n",
       " [[-1, 13], [-1, 47], [-1, 215]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[5, 3], [-1, 13], [2, 35], [-1, 47], [-1, 215]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 47], [-1, 214]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [5, 3], [3, 8], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[2, 2], [-1, 47], [5, 67]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 4], [-1, 11], [-1, 47]],\n",
       " [[-1, 10], [-1, 47], [-1, 207]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[-1, 12], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 207]],\n",
       " [[1, 1], [2, 2], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 13], [-1, 15], [6, 27], [-1, 47]],\n",
       " [[-1, 13], [-1, 15], [6, 27], [-1, 47]],\n",
       " [[-1, 13], [-1, 16], [2, 18], [-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[1, 1], [3, 8], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 2], [-1, 47]],\n",
       " [[2, 3], [-1, 19], [-1, 47], [-1, 207]],\n",
       " [[5, 3], [5, 4], [-1, 6], [3, 8], [-1, 21], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[3, 8], [-1, 10], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[3, 8], [6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[3, 8], [6, 27], [-1, 47]],\n",
       " [[-1, 47], [-1, 208]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 6], [-1, 25], [-1, 47], [-1, 207], [-1, 284]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[3, 8], [6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[5, 3], [-1, 47], [-1, 207], [-1, 208]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 15], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[5, 3], [3, 8], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 47], [-1, 207]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47], [-1, 215]],\n",
       " [[4, 28], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 6], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[-1, 10], [-1, 25], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [3, 8], [-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 15], [-1, 47]],\n",
       " [[1, 1], [-1, 15], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47], [-1, 215]],\n",
       " [[-1, 47], [-1, 215]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[-1, 47]],\n",
       " [[6, 27], [-1, 47], [-1, 207]],\n",
       " [[-1, 19], [-1, 47], [-1, 207]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 47]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[-1, 13], [-1, 47], [-1, 183]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[-1, 47], [-1, 215]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 6], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[3, 8], [-1, 10], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47], [-1, 207]],\n",
       " [[1, 1], [-1, 6], [-1, 47], [-1, 207]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[2, 2], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[3, 8], [-1, 10], [-1, 13], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[3, 8], [6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 6], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[5, 3], [5, 4], [-1, 47], [-1, 208]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[1, 1], [3, 8], [-1, 15], [-1, 47]],\n",
       " [[-1, 47], [-1, 204]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 10], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[2, 35], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [5, 4], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 4], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[1, 1], [4, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[-1, 10], [-1, 47]],\n",
       " [[-1, 25], [-1, 47]],\n",
       " [[1, 1], [4, 3], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[5, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 10], [-1, 47], [-1, 207]],\n",
       " [[1, 1], [-1, 13], [-1, 15], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47], [-1, 215]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [5, 4], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[2, 18], [-1, 47]],\n",
       " [[2, 2], [-1, 19], [-1, 47]],\n",
       " [[2, 2], [-1, 19], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [4, 3], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 15], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [5, 4], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [3, 8], [-1, 47]],\n",
       " [[3, 8], [-1, 47]],\n",
       " [[-1, 23], [-1, 47]],\n",
       " [[1, 1], [-1, 13], [-1, 25], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[-1, 15], [-1, 23], [-1, 47]],\n",
       " [[-1, 13], [-1, 15], [6, 27], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[-1, 13], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[6, 27], [-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[2, 2], [-1, 47]],\n",
       " [[-1, 47]],\n",
       " [[1, 1], [-1, 47]],\n",
       " [[1, 1], [5, 4], [-1, 47]],\n",
       " [[1, 1], [5, 3], [-1, 47]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 31], [-1, 206], [-1, 215], [-1, 284]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 11], [-1, 13], [-1, 15], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 11], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 15], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 32], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 11], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 31], [-1, 206], [-1, 215], [-1, 284]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[4, 3], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [2, 35], [-1, 206]],\n",
       " [[-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 32], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[2, 0], [-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 32], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [0, 35], [2, 35], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [4, 28], [-1, 206]],\n",
       " [[-1, 30], [-1, 39], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[12, 0], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 15], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 32], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 37], [-1, 206]],\n",
       " [[12, 0], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [4, 36], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206], [-1, 215]],\n",
       " [[3, 8], [-1, 10], [4, 36], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 32], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206], [-1, 218]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 15], [4, 55], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 11], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [4, 55], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 13], [-1, 206], [-1, 215]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 11], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[2, 0], [4, 3], [-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [2, 35], [-1, 206], [-1, 215]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[-1, 206]],\n",
       " [[12, 0], [-1, 7], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [2, 0], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[3, 8], [-1, 7], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[-1, 206], [-1, 215]],\n",
       " [[-1, 6], [3, 8], [4, 36], [4, 55], [-1, 206]],\n",
       " [[2, 0], [3, 8], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 10], [4, 36], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206], [-1, 208]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[2, 0], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[5, 3], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 13], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[12, 0], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[2, 0], [3, 8], [-1, 206]],\n",
       " [[-1, 206]],\n",
       " [[1, 1], [3, 8], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[4, 3], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 11], [-1, 15], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 7], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 7], [-1, 205], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 66], [-1, 206]],\n",
       " [[1, 1], [5, 3], [5, 4], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [4, 36], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 15], [-1, 206], [-1, 215]],\n",
       " [[4, 3], [3, 8], [-1, 10], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206], [-1, 215]],\n",
       " [[3, 8], [4, 36], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 15], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [-1, 206]],\n",
       " [[2, 0], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [4, 36], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 7], [3, 66], [-1, 206], [-1, 208]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[4, 3], [-1, 6], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 10], [4, 36], [2, 41], [-1, 206]],\n",
       " [[4, 3], [-1, 6], [3, 8], [-1, 10], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [2, 35], [3, 66], [-1, 205], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [11, 162], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[-1, 206], [-1, 215]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[2, 0], [3, 8], [4, 36], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 11], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [4, 36], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[4, 3], [3, 8], [-1, 11], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [-1, 206]],\n",
       " [[1, 1], [3, 8], [3, 66], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [0, 35], [2, 35], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 11], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 15], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 6], [3, 8], [3, 66], [-1, 206]],\n",
       " [[1, 1], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [4, 36], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[-1, 6], [3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 30], [-1, 206]],\n",
       " [[-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 206]],\n",
       " [[1, 1], [3, 8], [-1, 206]],\n",
       " [[-1, 10], [-1, 30], [-1, 206]],\n",
       " [[3, 8], [-1, 30], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [4, 36], [3, 66], [-1, 206]],\n",
       " [[3, 8], [3, 66], [-1, 206]],\n",
       " [[3, 8], [-1, 10], [-1, 30], [-1, 206]],\n",
       " [[4, 7], [3, 38], [-1, 42]],\n",
       " [[12, 0], [3, 8], [-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[2, 7], [-1, 42]],\n",
       " [[1, 1], [3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[12, 7], [2, 35], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 13], [-1, 42], [-1, 215]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[2, 35], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[4, 7], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[2, 7], [-1, 42]],\n",
       " [[2, 7], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[2, 7], [3, 38], [-1, 42], [3, 66]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[1, 1], [3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42], [-1, 201]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42], [-1, 43]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42], [-1, 201]],\n",
       " [[-1, 39], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [4, 55]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 8], [-1, 42], [3, 66]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 39], [-1, 42], [-1, 201]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 39], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [-1, 201]],\n",
       " [[-1, 39], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 42], [2, 45], [3, 66]],\n",
       " [[3, 38], [-1, 42], [2, 58]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[12, 7], [-1, 42]],\n",
       " [[1, 1], [-1, 10], [3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [3, 66]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 15], [-1, 42], [-1, 284]],\n",
       " [[-1, 42], [-1, 46]],\n",
       " [[-1, 42]],\n",
       " [[2, 3], [3, 38], [-1, 42]],\n",
       " [[1, 1], [3, 38], [-1, 42], [3, 66]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[4, 7], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 39], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[1, 1], [3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42], [3, 66]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 42], [3, 66]],\n",
       " [[4, 7], [3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42], [2, 58]],\n",
       " [[-1, 42]],\n",
       " [[3, 8], [-1, 26], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 42], [-1, 57], [3, 66]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 8], [-1, 42]],\n",
       " [[-1, 39], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [2, 58]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [2, 58]],\n",
       " [[-1, 42]],\n",
       " [[-1, 42], [3, 66]],\n",
       " [[3, 38], [-1, 42]],\n",
       " [[3, 38], [-1, 42], [-1, 201]],\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dish name for all recipes\n",
    "Dish_name = []\n",
    "for p in IngreLabel:\n",
    "    tmp = p[0]\n",
    "    tmp = tmp.split('/')\n",
    "    Dish_name.append(int(tmp[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 172)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(Dish_name), max(Dish_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cross entropy between image representation p and target representation t\n",
    "\n",
    "def loss_function(p_ingre, p_cut, t_ingre, t_cut):\n",
    "    \n",
    "    # loss of ingredients\n",
    "    loss = gpu(nn.BCEWithLogitsLoss())\n",
    "    t_ingre = gpu(t_ingre.float())\n",
    "    p_ingre = gpu(p_ingre.float())\n",
    "    L1 = loss(p_ingre,t_ingre)\n",
    "    \n",
    "    # ground-truth ingredient set\n",
    "    a = t_ingre.nonzero().view(-1)\n",
    "  \n",
    "    # conditional cutting tensor\n",
    "    new_p_cut = torch.zeros(p_cut.size())\n",
    "    for j in a.cpu().numpy():\n",
    "        for i in range(p_cut.size(1)):\n",
    "            new_p_cut[j][i] = p_cut[j][i]\n",
    "    # loss of cutting\n",
    "    t_cut = gpu(t_cut.float())\n",
    "    new_p_cut = gpu(new_p_cut.float())\n",
    "    L2 = loss(new_p_cut, t_cut)\n",
    "  \n",
    "    L = L1 + L2\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(Q_ingre, Q_cut, R):\n",
    "    simi = 0\n",
    "    for doublet in R:\n",
    "        ing, cut = doublet[0], doublet[1]\n",
    "    simi += Q_ingre[ing] + cc_rate * Q_cut[cut][ing]\n",
    "    simi /= len(R)\n",
    "  \n",
    "    return simi\n",
    "\n",
    "def pred_dish(Q_ingre,Q_cut,all_recipe):\n",
    "    simi = 0\n",
    "    res = -1\n",
    "    for idx, recipe in enumerate(all_recipe):\n",
    "        tmp = similarity(Q_ingre, Q_cut, recipe)\n",
    "        if tmp > simi:\n",
    "            simi = tmp\n",
    "            res = idx\n",
    "    return(Dish_name[res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n",
    "model = gpu(model_vgg.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat_t(dataset):\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    paths_list = []\n",
    "    for data in dataset:\n",
    "        inputs,labels,paths = data\n",
    "        inputs = gpu(inputs)\n",
    "        labels = gpu(labels)\n",
    "        paths = list(paths)\n",
    "        x = model(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "        paths_list.extend(paths)\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list,paths_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 24s, sys: 6min 34s, total: 17min 58s\n",
      "Wall time: 18min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train, paths_train = preconvfeat_t(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 54s, sys: 1min 5s, total: 2min 59s\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_val,labels_val, paths_val = preconvfeat_t(dset_loaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 42s, sys: 3min 16s, total: 8min 58s\n",
      "Wall time: 8min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_test,labels_test, paths_test = preconvfeat_t(dset_loaders['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ./cross_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(os.path.join('./cross_model','feat_train.bc'),conv_feat_train)\n",
    "save_array(os.path.join('./cross_model','labels_train.bc'),labels_train)\n",
    "save_array(os.path.join('./cross_model','paths_train.bc'),paths_train)\n",
    "save_array(os.path.join('./cross_model','feat_val.bc'),conv_feat_val)\n",
    "save_array(os.path.join('./cross_model','labels_val.bc'),labels_val)\n",
    "save_array(os.path.join('./cross_model','paths_val.bc'),paths_val)\n",
    "# save_array(os.path.join('./cross_model','feat_test.bc'),conv_feat_test)\n",
    "# save_array(os.path.join('./cross_model','labels_test.bc'),labels_test)\n",
    "# save_array(os.path.join('./cross_model','paths_test.bc'),paths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_tr = load_array('./cross_model/feat_train.bc')\n",
    "labels_tr = load_array('./cross_model/labels_train.bc')\n",
    "paths_tr = load_array('./cross_model/paths_train.bc')\n",
    "conv_feat_v = load_array('./cross_model/feat_val.bc')\n",
    "labels_v = load_array('./cross_model/labels_val.bc')\n",
    "paths_v = load_array('./cross_model/paths_val.bc')\n",
    "# conv_feat_te = load_array(data_dir+'/cross_model/conv_feat_test.bc')\n",
    "# labels_te = load_array(data_dir+'/cross_model/labels_test.bc')\n",
    "# paths_te = load_array(data_dir+'/cross_model/paths_test.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(conv_feat,labels,paths,batch_size=64,shuffle=True):\n",
    "    labels = np.array(labels)\n",
    "    newpaths = []\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(conv_feat))\n",
    "        conv_feat = conv_feat[index]\n",
    "        labels = labels[index]\n",
    "#         k = 0\n",
    "        for i in index:\n",
    "            newpaths.append(paths[i])\n",
    "#             k += 1\n",
    "    for idx in range(0,len(conv_feat),batch_size):\n",
    "        yield(conv_feat[idx:idx+batch_size],labels[idx:idx+batch_size],newpaths[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "epochs = 10\n",
    "\n",
    "optimizer = optim.SGD(embedding().parameters(), learning_rate)\n",
    "\n",
    "def train_model_emb(model,size_train,size_val,conv_feat_train=None,labels_train=None, paths_train=None, \n",
    "                conv_feat_val=None,labels_val=None,paths_val=None,batch_size=64,epochs=1,optimizer=None,\n",
    "                    train=True,shuffle=True):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    LOSS = []\n",
    "    ACC = []\n",
    "    LOSS_V = []\n",
    "    ACC_V = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        batches = data_gen(conv_feat=conv_feat_train,labels=labels_train,paths=paths_train,batch_size=batch_size,\n",
    "                           shuffle=shuffle)\n",
    "\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        k = 1\n",
    "        for inputs,classes,paths in batches:\n",
    "            inputs, classes = gpu(torch.from_numpy(inputs)), gpu(torch.from_numpy(classes))          \n",
    "            \n",
    "            fea_embeddings, ing_embeddings, cut_embeddings  = model(inputs)\n",
    "            \n",
    "            loss = 0\n",
    "            preds = []\n",
    "            p_ingres,p_cuts = pooling(ing_embeddings, cut_embeddings)\n",
    "            for i in range(fea_embeddings.size(0)):  #batch_size\n",
    "                fea_emb = fea_embeddings[i]\n",
    "                ing_emb = ing_embeddings[i]\n",
    "                cut_emb = cut_embeddings[i]\n",
    "                t_ingre = Get_ingre(paths[i])\n",
    "                t_cut = Get_cut(t_ingre)\n",
    "                p_ingre = p_ingres[i]\n",
    "                p_cut = p_cuts[i]\n",
    "                # loss\n",
    "                l = loss_function(p_ingre, p_cut, t_ingre, t_cut)\n",
    "                # similarity, retrival\n",
    "                pred = pred_dish(p_ingre,p_cut,All_recipe)\n",
    "#                 loss.append(l)\n",
    "                loss += l\n",
    "                preds.append(pred)\n",
    "                print('{}-th over 64 of batch {}'.format(i+1,k))\n",
    "#                 print(type(loss))\n",
    "#                 print(loss)\n",
    "            preds = gpu(torch.from_numpy(np.asarray(preds)))\n",
    "#             loss = gpu(torch.autograd.Variable(torch.from_numpy(np.asarray([loss]))))\n",
    "            \n",
    "            if optimizer is None:\n",
    "                raise ValueError('Pass optimizer for train mode')\n",
    "            optimizer = optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "            k += 1\n",
    "        epoch_loss = running_loss / size_train\n",
    "        epoch_acc = running_corrects.data.item() / size_train\n",
    "        LOSS.append(epoch_loss)\n",
    "        ACC.append(epoch_acc)\n",
    "        print('Epoch: {} Training Loss: {:.4f} Training Acc: {:.4f}'.format(\n",
    "                     epoch+1, epoch_loss, epoch_acc))\n",
    "        \n",
    "        \n",
    "        batches = data_gen(conv_feat=conv_feat_val,labels=labels_val,paths=paths_val,shuffle=shuffle)\n",
    "        total = 0\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs,classes,paths in batches:\n",
    "            inputs,classes = gpu(torch.from_numpy(inputs)),gpu(torch.from_numpy(classes))       \n",
    "                                        \n",
    "            fea_embeddings, ing_embeddings, cut_embeddings  = model(inputs)\n",
    "            loss = 0.0\n",
    "            preds = []\n",
    "            p_ingres,p_cuts = pooling(ing_embeddings, cut_embeddings)\n",
    "            for i in range(fea_embeddings.size(0)):\n",
    "                fea_emb = fea_embeddings[i]\n",
    "                ing_emb = ing_embeddings[i]\n",
    "                cut_emb = cut_embeddings[i]\n",
    "                p_ingre = p_ingres[i]\n",
    "                p_cut = p_cuts[i]\n",
    "                t_ingre = Get_ingre(paths[i])\n",
    "                t_cut = Get_cut(t_ingre)\n",
    "                # loss\n",
    "                l = loss_function(p_ingre, p_cut, t_ingre, t_cut)\n",
    "                # similarity, retrival           \n",
    "                pred = pred_dish(p_ingre,p_cut,All_recipe)\n",
    "#                 loss.append(l)\n",
    "                loss += l\n",
    "                preds.append(pred)\n",
    "                \n",
    "#             loss = torch.FloatTensor(loss)\n",
    "#             preds = torch.FloatTensor(preds)\n",
    "            preds = gpu(torch.from_numpy(np.asarray(preds)))\n",
    "#             loss = gpu(torch.autograd.Variable(torch.from_numpy(np.asarray([loss]))))\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / size_val\n",
    "        epoch_acc = running_corrects.data.item() / size_val\n",
    "        LOSS_V.append(epoch_loss)\n",
    "        ACC_V.append(epoch_acc)\n",
    "        print('Epoch: {} Validation Loss: {:.4f} Validation Acc: {:.4f}'.format(\n",
    "                     epoch+1, epoch_loss, epoch_acc))\n",
    "        \n",
    "#     return \n",
    "    return LOSS, ACC, LOSS_V, ACC_V\n",
    "#     return LOSS, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66071"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-th over 64 of batch 1\n",
      "2-th over 64 of batch 1\n",
      "3-th over 64 of batch 1\n",
      "4-th over 64 of batch 1\n",
      "5-th over 64 of batch 1\n",
      "6-th over 64 of batch 1\n",
      "7-th over 64 of batch 1\n",
      "8-th over 64 of batch 1\n",
      "9-th over 64 of batch 1\n",
      "10-th over 64 of batch 1\n",
      "11-th over 64 of batch 1\n",
      "12-th over 64 of batch 1\n",
      "13-th over 64 of batch 1\n",
      "14-th over 64 of batch 1\n",
      "15-th over 64 of batch 1\n",
      "16-th over 64 of batch 1\n",
      "17-th over 64 of batch 1\n",
      "18-th over 64 of batch 1\n",
      "19-th over 64 of batch 1\n",
      "20-th over 64 of batch 1\n",
      "21-th over 64 of batch 1\n",
      "22-th over 64 of batch 1\n",
      "23-th over 64 of batch 1\n",
      "24-th over 64 of batch 1\n",
      "25-th over 64 of batch 1\n",
      "26-th over 64 of batch 1\n",
      "27-th over 64 of batch 1\n",
      "28-th over 64 of batch 1\n",
      "29-th over 64 of batch 1\n",
      "30-th over 64 of batch 1\n",
      "31-th over 64 of batch 1\n",
      "32-th over 64 of batch 1\n",
      "33-th over 64 of batch 1\n",
      "34-th over 64 of batch 1\n",
      "35-th over 64 of batch 1\n",
      "36-th over 64 of batch 1\n",
      "37-th over 64 of batch 1\n",
      "38-th over 64 of batch 1\n",
      "39-th over 64 of batch 1\n",
      "40-th over 64 of batch 1\n",
      "41-th over 64 of batch 1\n",
      "42-th over 64 of batch 1\n",
      "43-th over 64 of batch 1\n",
      "44-th over 64 of batch 1\n",
      "45-th over 64 of batch 1\n",
      "46-th over 64 of batch 1\n",
      "47-th over 64 of batch 1\n",
      "48-th over 64 of batch 1\n",
      "49-th over 64 of batch 1\n",
      "50-th over 64 of batch 1\n",
      "51-th over 64 of batch 1\n",
      "52-th over 64 of batch 1\n",
      "53-th over 64 of batch 1\n",
      "54-th over 64 of batch 1\n",
      "55-th over 64 of batch 1\n",
      "56-th over 64 of batch 1\n",
      "57-th over 64 of batch 1\n",
      "58-th over 64 of batch 1\n",
      "59-th over 64 of batch 1\n",
      "60-th over 64 of batch 1\n",
      "61-th over 64 of batch 1\n",
      "62-th over 64 of batch 1\n",
      "63-th over 64 of batch 1\n",
      "64-th over 64 of batch 1\n",
      "1-th over 64 of batch 2\n",
      "2-th over 64 of batch 2\n",
      "3-th over 64 of batch 2\n",
      "4-th over 64 of batch 2\n",
      "5-th over 64 of batch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5f9c9bd47594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mconv_feat_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconv_feat_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpaths_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpaths_v\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             epochs=30,optimizer=optimizer,train=True,shuffle=True))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-bdce79ed330e>\u001b[0m in \u001b[0;36mtrain_model_emb\u001b[0;34m(model, size_train, size_val, conv_feat_train, labels_train, paths_train, conv_feat_val, labels_val, paths_val, batch_size, epochs, optimizer, train, shuffle)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ingre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_cut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_ingre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_cut\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;31m# similarity, retrival\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_dish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_ingre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_cut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mAll_recipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;31m#                 loss.append(l)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9141c0fa0d6f>\u001b[0m in \u001b[0;36mpred_dish\u001b[0;34m(Q_ingre, Q_cut, all_recipe)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_recipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_ingre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_cut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msimi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0msimi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9141c0fa0d6f>\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(Q_ingre, Q_cut, R)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdoublet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0ming\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoublet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoublet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msimi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mQ_ingre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ming\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcc_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mQ_cut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ming\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msimi\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cutDim = 14\n",
    "ingDim = 353\n",
    "cc_rate = 0.2\n",
    "\n",
    "LOSS, ACC, LOSS_V, ACC_V = (train_model_emb(model=gpu(embedding()),\n",
    "            size_train=dset_sizes['train'],size_val=dset_sizes['val'],\n",
    "            conv_feat_train=conv_feat_tr,labels_train=labels_tr,\n",
    "            paths_train=paths_tr,\n",
    "            conv_feat_val=conv_feat_v,labels_val=labels_v,\n",
    "            paths_val=paths_v,batch_size = batch_size,\n",
    "            epochs=30,optimizer=optimizer,train=True,shuffle=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "E = np.arange(50)+1\n",
    "plt.plot(E,LOSS,label='training')\n",
    "plt.plot(E,LOSS_V,label='validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(E,ACC,label='trianing')\n",
    "plt.plot(E,ACC_V,label='validation')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
